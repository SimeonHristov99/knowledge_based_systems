######################################################################################################
# General
######################################################################################################

Resources:

	- https://www.youtube.com/playlist?list=PLL6fCAGvk5rbVYleS86TCdTCrX7N7Zi0n


State Space / State Graph:
	- give an example:
		- of what a state is: with the 8-block problem
		- of those terms with a simple tree
			- n => node from the state graph / state from the state space
			- b => branching factor
			- m => maximum depth
			- d => depth of shallowest goal
			- Where are these explained? Topic 2.2, Page 29


######################################################################################################
# Task 1
######################################################################################################

	- Answer (table): Topic 2.2, Page 29
	
	- Classical Searching:
	
		- A search algorithm is complete if it is guaranteed to find a solution if there is one.
		- A search algorithm is optimal for some cost constraint if it can find a solution and that solution minimizes that cost g(n). If the algorithm is optimal, than it must be complete.
			- g(n) # The cost from start to current_state.
				- not a heuristic, because it doesn't tell us anything about the goal state(s).
					- heuristic: A metric that gives information about the goal state(s).
				- if current_state == goal: g(n) is named C*

		- uninformed (blind) (access only to the problem definition):

			- DFS (depth-first search) <= Moto: "Go as deep as you can!":

				- DLS (Depth-Limited Search):				
					- we use a cutoff line, limiting the searching to depth l

				- IDS (Iterative-Deepening):
					- use this if a lot of states and you don't know the depth of the goal
					- Problem: What if b = inf?
						Yes, because we would need infinite time to search level 1.
				
				- Problems:
					- Path is not guaranteed to be the cheapest.
					- What if m = inf ?
					- What if b == inf ?

			- UCS (Uniform-Cost search) <= Moto: "Cheaper is better!":

				- Sorts frontier according to g(n).
					- Guaranteed to produce the cheapest path.

				- If g(n) == 1 for all n, then we get BFS!
					- Problem: What if b = inf ?
				
				- Problem:
					- Frontier can become too big.

		- informed:

			- h(n) # The cost from current_state to finish.
				- heuristic!!
				- 0 < h(n) <= real_cost

			- Best-First search:
				- uniform-cost search but for h(n)
				- expands node with min h(n)

			- A* search:
				- if you can, ALWAYS use this
				- f(n) = h(n) + g(n)


	- Beyond Classical Searching:
		- Hill climbing:
			- expands only the best node, without keeping track of anything, i.e. frontier or path cost.

		- Beam search:
			- Hill climging but keeps the best k paths in a frontier.


	- Final notes:
		- What is the difference between Hill climbing vs. Beam search vs. Best-first search?


######################################################################################################
# Task 2
######################################################################################################

a -> Topic 2.2, page 18, answer=(s a b c g)
b -> Topic 3, page 6, answer=(s d e g)
c -> Topic 3, page 17, answer=(s a b c g)


######################################################################################################
# Task 3
######################################################################################################

Topic: 5
	- minimax stars from page 4
	- alpha-beta stars from page 12

Adversial Search === Games
	- Mini-max
		- DFS
		- Alpha-beta:
			- go DFS till leaf nodes putting -inf for alpha and +inf for beta
			- if alpha is parent and alpha > beta => PRUNE
			- if beta is parent and alpha > beta => PRUNE
			- only when you get a concrete value for a node do you offer it upwards


######################################################################################################
# Task 4
######################################################################################################

Topic: 4
	- definitions for selection and crossover: 4
	- definitions for mutation: 5
	- example of single-point crossover: page 8, 10
	- example of double crossover: page 11, 16
	- example of arithmetic crossover: page 12
	- example of mutation: page 18

Laptop 500 2.5
Phone 1500 0.5
Headphones 600 0.1

max_kg = 2

Population
individual=[1, 1, 1] => fitness=0
individual=[0, 0, 0] => fitness=0
individual=[0, 0, 1] => fitness=600

Single-point:
p1=[0, 0, 1]
p2=[1, 1, 1]
    ^

c1=[1, 0, 1]
c2=[0, 1, 1]

Double-point:
p1=[0, 0, 1, 0, 0, 1, 1, 0]
p2=[1, 1, 1, 1, 1, 1, 0, 0]
          ^           ^

c1=[1, 1, 1, 0, 0, 1, 1, 0]
c2=[0, 0, 1, 1, 1, 1, 0, 0]

Arithmetic:
p1=[0, 0, 1, 0, 0, 1, 1, 0]
p2=[1, 1, 1, 1, 1, 1, 0, 0]

c1=[0, 0, 1, 0, 0, 1, 0, 0]
c2=[1, 1, 1, 1, 1, 1, 1, 0]

Mutation:
c1=[1, 0, 1]
c2=[0, 1, 1]

mc1=[1, 0, 1]
mc2=[1, 0, 1]

Genetic algorithms:
	- variant of stochastic beam search - new states are "bred" of old states.
	- selection.
	- crossover.
	- mutation.


######################################################################################################
# Task 5
######################################################################################################

answer:b, why? no frontier. Topic 3, page 14


######################################################################################################
# Task 6
######################################################################################################

Topic 6

Types of constraints: Page 7

Backtracking: 13

Arc Consistency-3: Page 29


######################################################################################################
# Task 7
######################################################################################################

Topic 8
Page 11

######################################################################################################
# Task 8
######################################################################################################

Topic 8
Page 12
